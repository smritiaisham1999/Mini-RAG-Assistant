import streamlit as st
import uuid
import os
import shutil  # File operations ke liye (jo pehle main.py me tha)

# --- LOCAL MODULE IMPORTS (Direct Backend Logic) ---
# Hum ab requests use nahi karenge, balkay direct functions call karenge
from rag_engine import RAGManager
from database import init_db, add_message, get_chat_history

# --- PAGE CONFIGURATION ---
st.set_page_config(
    page_title="Enterprise RAG Agent",
    page_icon="ðŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- SYSTEM INITIALIZATION (Backend Setup inside Frontend) ---
# Ye logic pehle main.py ke startup me thi, ab yahan session state me hogi
if "rag_manager" not in st.session_state:
    st.session_state.rag_manager = RAGManager()
    
    # Database aur Data folder initialize karein
    init_db()
    os.makedirs("data", exist_ok=True)

# --- SESSION STATE INITIALIZATION ---
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- HELPER: SMART KEY LOADER ---
def get_api_key(provider_type):
    """
    Tries to load API Key from:
    1. Streamlit Secrets (Best for Cloud)
    2. Environment Variables (Best for Local)
    3. Return None if not found (Falls back to Manual Input)
    """
    key_name = "OPENAI_API_KEY" if provider_type == "openai" else "GOOGLE_API_KEY"
    
    # Check Streamlit Secrets first
    if key_name in st.secrets:
        return st.secrets[key_name]
    
    # Check OS Environment
    if os.getenv(key_name):
        return os.getenv(key_name)
        
    return None

# --- SIDEBAR: CONFIGURATION ---
with st.sidebar:
    st.title("ðŸŽ›ï¸ Control Panel")
    
    # 1. User Identity
    st.subheader("ðŸ‘¤ User Profile")
    username = st.text_input(
        "Username", 
        value=st.session_state.get("username", ""), 
        placeholder="e.g., admin_user",
        help="Used for Role-Based Access Control (RBAC)"
    )
    if username:
        st.session_state.username = username # Persist in session

    st.divider()

    # 2. AI Provider Settings
    st.subheader("ðŸ§  Model Settings")
    provider_option = st.selectbox("Select AI Provider", ["OpenAI (GPT-4o)", "Google (Gemini 1.5)"])
    provider_key_type = "openai" if "OpenAI" in provider_option else "gemini"

    # Smart Key Logic
    system_key = get_api_key(provider_key_type)
    
    if system_key:
        api_key = system_key
        st.success(f"âœ… {provider_key_type.title()} Key Active (System Managed)")
    else:
        api_key = st.text_input(f"ðŸ”‘ Enter {provider_key_type.title()} Key", type="password")
        if not api_key:
            st.warning("âš ï¸ API Key required for processing.")

    st.divider()

    # 3. Document Ingestion
    st.subheader("ðŸ“‚ Knowledge Base")
    privacy_mode = st.radio("Access Level:", ("Private (Session Only)", "Public (Organization)"), index=0)
    privacy_val = "private" if "Private" in privacy_mode else "public"
    
    uploaded_files = st.file_uploader("Upload Documents (PDF/DOCX/TXT)", accept_multiple_files=True)
    
    if st.button("ðŸš€ Process & Ingest", type="primary"):
        if not username:
            st.error("âŒ Username is required!")
        elif not api_key:
            st.error("âŒ API Key is missing!")
        elif not uploaded_files:
            st.error("âŒ Please select files first.")
        else:
            with st.status("Processing Documents...", expanded=True) as status:
                try:
                    # --- STEP 1: SAVE FILES LOCALLY (Mimicking main.py logic) ---
                    st.write("ðŸ“¥ Saving files locally...")
                    saved_paths = []
                    
                    for uploaded_file in uploaded_files:
                        # File path define karein
                        file_location = f"data/{uploaded_file.name}"
                        
                        # File write karein
                        with open(file_location, "wb") as buffer:
                            buffer.write(uploaded_file.getbuffer())
                        
                        saved_paths.append(file_location)

                    # --- STEP 2: PROCESS FILES (Direct Call to RAGManager) ---
                    st.write("âš™ï¸ Parsing and Embedding...")
                    
                    # Direct call instead of requests.post
                    num_chunks = st.session_state.rag_manager.process_files(
                        file_paths=saved_paths,
                        username=username,
                        privacy=privacy_val,
                        provider=provider_key_type,
                        api_key=api_key
                    )
                    
                    status.update(label="âœ… Ingestion Complete!", state="complete", expanded=False)
                    st.success(f"Successfully processed {len(saved_paths)} files into {num_chunks} chunks for user '{username}' ({privacy_val} mode).")
                    
                except Exception as e:
                    status.update(label="âŒ Processing Failed", state="error")
                    st.error(f"Error during processing: {str(e)}")

# --- MAIN CHAT INTERFACE ---

# Header
col1, col2 = st.columns([3, 1])
with col1:
    st.title("ðŸ¤– Corporate RAG Assistant")
    st.caption("Secure Retrieval Augmented Generation with Precision Metrics")
with col2:
    if username:
        st.markdown(f"**Logged in as:** `{username}`")
        st.markdown(f"**Mode:** `{privacy_mode}`")

st.divider()

# Display Chat History
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        
        # Advanced Metrics Display for Assistant
        if msg.get("role") == "assistant" and msg.get("confidence", 0) > 0:
            c_score = msg["confidence"]
            
            # Metric Columns
            m_col1, m_col2, m_col3 = st.columns([2, 2, 4])
            with m_col1:
                st.metric("Confidence", f"{c_score}%")
            with m_col2:
                # Color coding based on score
                p_color = "green" if c_score > 70 else "orange" if c_score > 40 else "red"
                st.caption(f"Grounding Health: :{p_color}[{p_color.upper()}]")
                st.progress(int(c_score))
            
            # Sources Expander
            with st.expander("ðŸ“š View Verified Sources (Evidence)"):
                sources = msg.get("sources", [])
                if sources:
                    for idx, src in enumerate(sources[:2]): # Limit to top 2
                        st.markdown(f"**{idx+1}. {src['source']}** (Match: {src['score']}%)")
                        st.info(f"{src['content'][:250]}...") # Truncate text
                else:
                    st.write("No direct sources cited from documents.")

# Input Field
if prompt := st.chat_input("Ask a question about your uploaded documents..."):
    if not api_key:
        st.toast("âŒ API Key is missing! Check sidebar.", icon="âš ï¸")
    elif not username:
        st.toast("âŒ Username is required! Check sidebar.", icon="ðŸ‘¤")
    else:
        # Add User Message
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Generate Response
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            
            with st.spinner("ðŸ§  Analyzing Knowledge Base..."):
                try:
                    # --- CORE LOGIC UPDATE (Replacing requests.post) ---
                    
                    # 1. Get History (Direct DB Call)
                    history = get_chat_history(st.session_state.session_id)
                    
                    # 2. Get Answer (Direct RAG Engine Call)
                    result = st.session_state.rag_manager.get_answer(
                        query=prompt,
                        history=history,
                        username=username,
                        provider=provider_key_type,
                        api_key=api_key
                    )
                    
                    # 3. Save Conversation to DB (Direct DB Call)
                    add_message(st.session_state.session_id, "user", prompt)
                    add_message(st.session_state.session_id, "assistant", result["answer"])
                    
                    # --- DATA EXTRACTION ---
                    answer = result["answer"]
                    confidence = result.get("confidence", 0)
                    sources = result.get("sources", [])
                    
                    # Display Answer
                    message_placeholder.markdown(answer)
                    
                    # Display Metrics if answer is grounded
                    if confidence > 0:
                        m_col1, m_col2, m_col3 = st.columns([2, 2, 4])
                        with m_col1:
                            st.metric("Confidence", f"{confidence}%")
                        with m_col2:
                            p_color = "green" if confidence > 70 else "orange"
                            st.caption("Relevance Score")
                            st.progress(int(confidence))
                        
                        with st.expander("ðŸ“š Verified Sources"):
                            for src in sources[:2]:
                                    st.markdown(f"**ðŸ“„ {src['source']}**")
                                    st.caption(f'"{src["content"][:200]}..."')
                                    st.divider()

                    # Save to Session State History
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": answer,
                        "confidence": confidence,
                        "sources": sources
                    })
                        
                except Exception as e:
                    message_placeholder.error(f"Processing Failed: {str(e)}")