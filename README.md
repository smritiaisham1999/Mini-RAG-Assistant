ğŸ§  Intelligent RAG Assistant

Grounded â€¢ Explainable â€¢ Anti-Hallucination AI




Version: 1.0
Type: Standalone AI Application

ğŸ“Œ Project Overview

Intelligent RAG Assistant is a Retrieval-Augmented Generation (RAG) system designed to deliver accurate, source-grounded, and confidence-aware answers from user-provided documents.

Unlike generic chatbots, this assistant:

âŒ Prevents hallucinations

ğŸ“Š Displays confidence scores

ğŸ“„ Cites document evidence

ğŸ” Answers only from uploaded files

ğŸ—ï¸ System Architecture

The application follows a Unified Monolithic Microservice Architecture, optimized for simplicity, performance, and rapid deployment.

ğŸ”¹ Core Components
Layer	Technology	Responsibility
UI Layer	Streamlit	Chat UI, file uploads, session handling
Orchestration	LangChain	Document parsing, chunking, retrieval logic
Vector Store	FAISS	Semantic similarity search
Persistence	SQLite	Chat history & session memory
LLM	OpenAI / Gemini	Context-grounded response generation

ğŸ“Œ Key Design Choice:
UI and backend logic are tightly coupled to reduce latency and complexity.

ğŸ”„ Retrieval & Generation Pipeline

The system strictly follows a Load â†’ Embed â†’ Retrieve â†’ Generate workflow.

1ï¸âƒ£ Ingestion

Supports PDF and DOCX

Text extracted and cleaned (formatting removed)

2ï¸âƒ£ Chunking

Chunk Size: 1000 characters

Overlap: 200 characters

Method: RecursiveCharacterTextSplitter

Ensures semantic continuity

3ï¸âƒ£ Vectorization

Embedding Size: 1536 dimensions

Model: OpenAI / Gemini Embeddings

Stored locally in FAISS

4ï¸âƒ£ Retrieval

Top 3 most relevant chunks

Based on semantic similarity

5ï¸âƒ£ Generation

LLM answers only from retrieved context

Strict prompt prevents external knowledge usage

ğŸ›¡ï¸ Confidence Scoring (Anti-Hallucination)

Every response includes a Confidence Score, computed using FAISS L2 Euclidean Distance.

ğŸ“ Formula
Score = 1 / (1 + (Distance Ã— 0.3)) Ã— 100

ğŸ§  Interpretation

100% â†’ Exact semantic match

Lower score â†’ Weaker relevance

< 30% â†’ Answer is blocked

ğŸš« If confidence drops below threshold, the system refuses to answer.

ğŸ§ª Example Scenarios
âœ… Scenario A: Successful Retrieval

User Query

What is the specific weightage for RAG integration?


AI Response

The RAG integration and functionality carries a weight of 40%.


Metadata

ğŸŸ¢ Confidence Score: 98.5%

ğŸ“„ Source File: Mini RAG Assistant (1).docx

ğŸ” Evidence:

"...Effectiveness of connecting retrieval... 40%..."

âŒ Scenario B: Hallucination Prevention

User Query

What is the CEO's salary?


AI Response

I cannot find this information in the provided documents.


Metadata

ğŸ”´ Confidence Score: 0%

âš ï¸ Reason: No semantic match found in vector database

âš™ï¸ Installation & Setup
ğŸ”§ Prerequisites

Python 3.10+

OpenAI / Gemini API Key

ğŸ“¥ Installation
git clone https://github.com/smritiaisham1999/Mini-RAG-Assistant.git
cd Mini-RAG-Assistant
pip install -r requirements.txt

â–¶ï¸ Run the App
streamlit run app.py

ğŸ¯ Key Features

âœ… Retrieval-Augmented Generation (RAG)

ğŸ§  Context-aware answers

ğŸ“Š Confidence scoring

ğŸ›¡ï¸ Anti-hallucination safeguards

ğŸ“„ Source-verified responses

ğŸ’¬ Chat history persistence

âš¡ Lightweight & local vector store

ğŸš€ Use Cases

Internal Knowledge Bases

Research Document QA

Compliance & Policy Verification

Academic & Technical Review

Secure Enterprise AI Assistants

ğŸ“Œ Project Status

ğŸ§ª Prototype (Stable)
Ready for:

Demo presentations

Client showcases

Fiverr / freelance delivery

Further production hardening
