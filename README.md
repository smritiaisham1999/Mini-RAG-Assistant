# ğŸ§  Intelligent RAG Assistant
> Grounded â€¢ Explainable â€¢ Anti-Hallucination AI

![Python](https://img.shields.io/badge/Python-3.11-blue)
![Streamlit](https://img.shields.io/badge/Streamlit-1.31-red)
![LangChain](https://img.shields.io/badge/LangChain-0.1-orange)
![FAISS](https://img.shields.io/badge/VectorDB-FAISS-green)
![Status](https://img.shields.io/badge/Status-Prototype-yellow)

**Version:** 1.0  
**Type:** Standalone AI Application  

---

## ğŸ“Œ Project Overview

**Intelligent RAG Assistant** is a **Retrieval-Augmented Generation (RAG)** system that delivers **accurate, source-grounded, and confidence-aware answers** from user-uploaded documents.

Unlike standard chatbots, this system:
- âŒ Prevents hallucinations
- ğŸ“Š Shows confidence scores
- ğŸ“„ Cites document sources
- ğŸ” Answers strictly from uploaded files

---

## ğŸ—ï¸ System Architecture

The application follows a **Unified Monolithic Microservice Architecture**, optimized for performance and simplicity.

### ğŸ”¹ Core Components

| Layer | Technology | Responsibility |
|------|-----------|---------------|
| UI | Streamlit | Chat UI, file upload, session state |
| Logic | LangChain | Chunking, retrieval, orchestration |
| Vector DB | FAISS | Semantic similarity search |
| Storage | SQLite | Chat history persistence |
| LLM | OpenAI / Gemini | Context-based generation |

---

## ğŸ”„ Retrieval & Generation Pipeline

The system follows a strict **Load â†’ Embed â†’ Retrieve â†’ Generate** workflow.

### 1ï¸âƒ£ Ingestion
- Supports **PDF** and **DOCX**
- Text extracted and cleaned

### 2ï¸âƒ£ Chunking
- Chunk Size: **1000 characters**
- Overlap: **200 characters**
- Uses `RecursiveCharacterTextSplitter`

### 3ï¸âƒ£ Vectorization
- Embedding Size: **1536**
- Stored locally in **FAISS**

### 4ï¸âƒ£ Retrieval
- Top **3** semantically closest chunks
- Based on cosine/L2 similarity

### 5ï¸âƒ£ Generation
- LLM answers **only from retrieved context**
- External knowledge strictly blocked

---

## ğŸ›¡ï¸ Confidence Scoring (Anti-Hallucination)

Each response includes a **Confidence Score** based on FAISS L2 distance.

### ğŸ“ Formula
Score = 1 / (1 + (Distance Ã— 0.3)) Ã— 100


### ğŸ” Rules
- **100%** â†’ Exact match
- **< 30%** â†’ Answer is rejected

---

## ğŸ§ª Example Scenarios

### âœ… Scenario A: Successful Retrieval

**User Query**
What is the specific weightage for RAG integration?



**System Answer**
The RAG integration and functionality carries a weight of 40%.



**Metadata**
- ğŸŸ¢ Confidence Score: **98.5%**
- ğŸ“„ Source: `Mini RAG Assistant (1).docx`
- ğŸ” Evidence snippet included

---

### âŒ Scenario B: Hallucination Prevention

**User Query**
What is the CEO's salary?


**System Answer**
I cannot find this information in the provided documents.



**Metadata**
- ğŸ”´ Confidence Score: **0%**
- âš ï¸ No semantic match found

---

## âš™ï¸ Installation & Setup

### ğŸ”§ Prerequisites
- Python **3.10+**
- OpenAI / Gemini API Key

### ğŸ“¥ Installation
```bash
git clone https://github.com/smritiaisham1999/Mini-RAG-Assistant.git
cd Mini-RAG-Assistant
pip install -r requirements.txt
â–¶ï¸ Run Application

streamlit run app.py
ğŸ¯ Key Features
âœ… Retrieval-Augmented Generation (RAG)

ğŸ›¡ï¸ Anti-hallucination guardrails

ğŸ“Š Confidence scoring

ğŸ“„ Source-grounded answers

ğŸ’¬ Persistent chat memory

âš¡ Lightweight local vector DB

ğŸš€ Use Cases
Enterprise Knowledge Bases

Research & Documentation QA

Compliance Verification

Secure Internal Assistants
